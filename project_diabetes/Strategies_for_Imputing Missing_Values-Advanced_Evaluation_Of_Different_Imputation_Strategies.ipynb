{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> AWS and Machine Learning </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data Cleaning - Strategies for Missing Values - Advanced Imputation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub Link: https://github.com/data-analytics-professionals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Jyputer Notebook, width: 100% \n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "cover = Image(filename=\"../project_diabetes/photos/Strategies for Missing Values â€“ Impute, Compare and Extensively Analyse.png\")\n",
    "display(cover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Data Acquisition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries (numpy, pandas) for data analysis and data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read the dataset 'diabetes.csv'\n",
    "df = pd.read_csv('data/pima_indians_diabetes.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample function return a random sample of n items from an axis of object.\n",
    "df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info function prints a concise summary of a DataFrame including the index dtype and column dtypes, non-null values and memory usage.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the description of the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Analyzing Missingness Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a nullity DataFrame df_nullity\n",
    "df_nullity = df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print nullity df_nullity\n",
    "df_nullity.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total of missing values\n",
    "print('Total Missing Values:\\n', df_nullity.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentage of missing values\n",
    "df_nullity_percent =  df_nullity.mean() * 100\n",
    "print('Percentage of Missing Values:\\n', df_nullity_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Visualize Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import missingno as msno\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(plt.style.available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Solarize_Light2 style\n",
    "plt.style.use('Solarize_Light2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot amount of missingness in the DataFrame\n",
    "msno.bar(\n",
    "    df,\n",
    "    figsize=(24, 10),\n",
    "    fontsize=16,\n",
    "    labels=None,\n",
    "    log=False,\n",
    "    color='limegreen',\n",
    "    inline=False,\n",
    "    filter=None,\n",
    "    n=0,\n",
    "    p=0,\n",
    "    sort=None,\n",
    "    ax=None\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plot the nullity matrix of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot nullity matrix of df\n",
    "msno.matrix(\n",
    "    df=df,\n",
    "    filter=None,\n",
    "    n=0,\n",
    "    p=0,\n",
    "    sort=None,\n",
    "    figsize=(25, 10),\n",
    "    width_ratios=(15, 1),\n",
    "    color=(1,0,0),\n",
    "    fontsize=16,\n",
    "    labels=None,\n",
    "    sparkline=True,\n",
    "    inline=False,\n",
    "    freq=None,\n",
    "    ax=None,\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort diabetes dataframe df on 'Serum_Insulin'\n",
    "sorted_values = df.sort_values(by=['Serum_Insulin'])\n",
    "\n",
    "# Visualize the missingness summary of sorted\n",
    "msno.matrix(\n",
    "    sorted_values,\n",
    "    filter=None,\n",
    "    n=0,\n",
    "    p=0,\n",
    "    sort=None,\n",
    "    figsize=(25, 10),\n",
    "    width_ratios=(15, 1),\n",
    "    color=(0,1,0),\n",
    "    fontsize=16,\n",
    "    labels=None,\n",
    "    sparkline=True,\n",
    "    inline=False,\n",
    "    freq=None,\n",
    "    ax=None,\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Correlations Between Missing Data (Missingness)\n",
    "\n",
    "> Remember we could find correlations between missing data and it helps us to gain a deeper understanding of the type of missing data.\n",
    "> It also provides suitable ways in which the missing values can be addressed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot missingness heatmap of diabetes DataFrame df\n",
    "msno.heatmap(\n",
    "    df,\n",
    "    inline=False,\n",
    "    filter=None,\n",
    "    n=0,\n",
    "    p=0,\n",
    "    sort=None,\n",
    "    figsize=(20, 12),\n",
    "    fontsize=16,\n",
    "    labels=True,\n",
    "    cmap='gist_rainbow',\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    cbar=True,\n",
    "    ax=None,\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot missingness dendrogram of diabetes DataFrame df\n",
    "msno.dendrogram(\n",
    "    df,\n",
    "    method='average',\n",
    "    filter=None,\n",
    "    n=0,\n",
    "    p=0,\n",
    "    orientation=None,\n",
    "    figsize=None,\n",
    "    fontsize=16,\n",
    "    inline=False,\n",
    "    ax=None,\n",
    ")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> More topics: \n",
    "    Writing useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "\n",
    "# Write a function that automates creating dummy values for missing data\n",
    "def fill_dummy_values(df, scaling_factor=0.075):\n",
    "    df_dummy = df.copy(deep=True)\n",
    "    for col_name in df_dummy:\n",
    "        \n",
    "        # Get column\n",
    "        col = df_dummy[col_name]\n",
    "        col_null = col.isnull()  \n",
    "        # Calculate number of missing values in column \n",
    "        num_nulls = col_null.sum()\n",
    "        # Calculate column range\n",
    "        col_range = col.max() - col.min()\n",
    "        # Shift dummy values to -2 and -1 , Remember rand generates values between 0 and 1\n",
    "        dummy_values = (rand(num_nulls) - 2) \n",
    "        # Scale dummy variables by scaling_factor and shift them towards col.min\n",
    "        dummy_values = dummy_values * scaling_factor * col_range + col.min()\n",
    "        \n",
    "        # Return dummy values\n",
    "        col[col_null] = dummy_values\n",
    "    return df_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Generate scatter plot with missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill dummy values in diabetes_dummy\n",
    "diabetes_dummy = fill_dummy_values(df)\n",
    "\n",
    "# Sum the nullity of Serum_Insulin and BMI (for coloring)\n",
    "nullity_Serum_Insulin_BMI = df.Serum_Insulin.isnull() + df.BMI.isnull()\n",
    "\n",
    "# Create a scatter plot of Serum_Insulin and BMI \n",
    "diabetes_dummy.plot(\n",
    "    x='Serum_Insulin', \n",
    "    y='BMI', \n",
    "    kind='scatter', \n",
    "    alpha=0.5,\n",
    "    # Set color to nullity of BMI and Skin_Fold\n",
    "    c=nullity_Serum_Insulin_BMI, \n",
    "    colormap='gist_rainbow',\n",
    "    title='Serum Insulin Vs BMI'    \n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Excellent! Now from above plot, lets make sure that we take a close look at how the missing values of Serum Insulin and BMI interact with eachther. We dont see any specfic corelation between these two variables that is of missingness of Skin_Insulin and BMI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let's find interaction between Serum_Insulin and BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the nullity of Skin_Fold and BMI\n",
    "nullity_Skin_Fold_BMI = df.Skin_Fold.isnull() + df.BMI.isnull()\n",
    "\n",
    "# Create a scatter plot of Skin Fold and BMI \n",
    "diabetes_dummy.plot(\n",
    "    x='Skin_Fold', \n",
    "    y='BMI', \n",
    "    kind='scatter', \n",
    "    alpha=0.5,                \n",
    "    \n",
    "    # Set color to nullity of BMI and Skin_Fold\n",
    "    c=nullity_Skin_Fold_BMI,\n",
    "    colormap='gist_rainbow',\n",
    "    \n",
    "    # Set title\n",
    "    title='Skin_Fold Vs BMI'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: We have already discussed and performed deletions tasks\n",
    "    Just to recall deletions are of two types \n",
    "    1. Pairwise deletion\n",
    "    2. Listwise deletion (Complete Case Analysis)\n",
    "    Note: used when the values are MCAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "Listwise and pairwise deletion are the most common techniques to handling missing data.  \n",
    "It is important to understand that in the vast majority of cases, an important assumption to using either of these techniques is that our data is missing completely \n",
    "at random (MCAR).\n",
    "\n",
    "In other words, the analysts or researchers needs to support that the probability of missing data on their dependent variable is unrelated to other independent variables \n",
    "as well as the dependent variable itself.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Mean Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of diabetes\n",
    "diabetes_mean = df.copy(deep=True)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create mean imputer object\n",
    "mean_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Impute mean values in the DataFrame diabetes_mean\n",
    "diabetes_mean.iloc[:, :] = mean_imputer.fit_transform(diabetes_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Median Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of diabetes\n",
    "diabetes_median = df.copy(deep=True)\n",
    "\n",
    "# Create median imputer object\n",
    "median_imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Impute median values in the DataFrame diabetes_median\n",
    "diabetes_median.iloc[:, :] = median_imputer.fit_transform(diabetes_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Mode Imputation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of diabetes\n",
    "diabetes_mode = df.copy(deep=True)\n",
    "\n",
    "# Create mode imputer object\n",
    "mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Impute mode values in the DataFrame diabetes_mode\n",
    "diabetes_mode.iloc[:, :] = mode_imputer.fit_transform(diabetes_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Imputing a constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of diabetes\n",
    "diabetes_constant = df.copy(deep=True)\n",
    "\n",
    "# Create comstant imputer object\n",
    "constant_imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "# Impute missing values to 0 in diabetes_constant\n",
    "diabetes_constant.iloc[:, :] = constant_imputer.fit_transform(diabetes_constant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Scatterplot of imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the nullity of Serum_Insulin and BMI (for coloring)\n",
    "nullity = df['Serum_Insulin'].isnull() + df['BMI'].isnull()\n",
    "\n",
    "# Create a scatter plot of Serum_Insulin and BMI from diabetes_mean \n",
    "diabetes_mean.plot(\n",
    "    x='Serum_Insulin', \n",
    "    y='BMI', \n",
    "    kind='scatter', \n",
    "    alpha=0.5,\n",
    "    c=nullity, \n",
    "    cmap='gist_rainbow',\n",
    "    title='Mean Imputation'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Comparision of Different Imputation Strategies and their Visual Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set nrows and ncols to 2\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(20,20))\n",
    "\n",
    "nullity = df['Serum_Insulin'].isnull() + df['BMI'].isnull()\n",
    "\n",
    "# Create a dictionary of imputations\n",
    "imputations = {\n",
    "    'Mean Imputation': diabetes_mean,\n",
    "    'Median Imputation': diabetes_median,\n",
    "    'Most Frequent Imputation': diabetes_mode,\n",
    "    'Constant Imputation' : diabetes_constant    \n",
    "}\n",
    "\n",
    "# Loop over flattened axes and imputations\n",
    "for ax, df_key in zip(axes.flatten(), imputations):\n",
    "    # Select and also set the title for a DataFrame\n",
    "    imputations[df_key].plot(\n",
    "        x='Serum_Insulin',\n",
    "        y='BMI',\n",
    "        kind='scatter',\n",
    "        alpha=0.5,\n",
    "        c=nullity,\n",
    "        cmap='gist_rainbow',\n",
    "        ax=ax,\n",
    "        colorbar=False,\n",
    "        title=df_key\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Summary:\n",
    "> Clear correlation between non-missing plotted features that are missed in our all imputation strategies and this creates a bias.\n",
    "> imputation strategies do preserve their basic statistical properties but donâ€™t account for their correlations.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To deal with this real world problem we need more robust and advanced imputation strategies. Lets use KNN from francyimpute package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> funcyimpute: A variety of matrix completion and imputation algorithms implemented in Python 3.6.\n",
    "> Algorithms\n",
    "> SimpleFill: Replaces missing entries with the mean or median of each column.\n",
    "\n",
    "> KNN: Nearest neighbor imputations which weights samples using the mean squared difference on features for which two rows both have observed data.\n",
    "\n",
    "> SoftImpute: Matrix completion by iterative soft thresholding of SVD decompositions. Inspired by the softImpute package for R, which is based on Spectral Regularization Algorithms for Learning Large Incomplete Matrices by Mazumder et. al.\n",
    "\n",
    "> IterativeImputer: A strategy for imputing missing values by modeling each feature with missing values as a function of other features in a round-robin fashion. A stub that links to scikit-learn's IterativeImputer.\n",
    "\n",
    "> IterativeSVD: Matrix completion by iterative low-rank SVD decomposition. Should be similar to SVDimpute from Missing value estimation methods for DNA microarrays by Troyanskaya et. al.\n",
    "\n",
    "> MatrixFactorization: Direct factorization of the incomplete matrix into low-rank U and V, with an L1 sparsity penalty on the elements of U and an L2 penalty on the elements of V. Solved by gradient descent.\n",
    "\n",
    "> NuclearNormMinimization: Simple implementation of Exact Matrix Completion via Convex Optimization by Emmanuel Candes and Benjamin Recht using cvxpy. Too slow for large matrices.\n",
    "\n",
    "> BiScaler: Iterative estimation of row/column means and standard deviations to get doubly normalized matrix. Not guaranteed to converge but works well in practice. Taken from Matrix Completion and Low-Rank SVD via Fast Alternating Least Squares.\n",
    "\n",
    ">> from fancyimpute import KNN, NuclearNormMinimization, SoftImpute, BiScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> KNN imputation </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Datasets always have features which are correlated. \n",
    "> Hence, it becomes important to consider them as a factor for imputing missing values. \n",
    "> Machine learning models use features in the DataFrame to find correlations and patterns and predict a selected feature.\n",
    "\n",
    "> One of the simplest and most efficient models is the K Nearest Neighbors. \n",
    "> It finds 'K' points most similar to the existing data points to impute missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KNN from fancyimpute\n",
    "from fancyimpute import KNN\n",
    "\n",
    "# Copy diabetes to diabetes_knn_imputed. This helps to compare results at later stage \n",
    "df_knn_imputed = df.copy(deep=True)\n",
    "\n",
    "# Initialize KNN\n",
    "knn_imputer = KNN()\n",
    "\n",
    "# Impute using fit_tranform on df_knn_imputed\n",
    "df_knn_imputed.iloc[:, :] = knn_imputer.fit_transform(df_knn_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> MICE (Mutiple Imputation by Chained Equations) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MICE: is a very robust and complex model for imputing missing values.\n",
    "> It imputes using multiple regressions over the data and takes an average value for filling in the missing feature for a data point.\n",
    "> it is known as IterativeImputer in the fancyimpute package as it performs multiple imputations on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import IterativeImputer from fancyimpute\n",
    "from fancyimpute import IterativeImputer\n",
    "\n",
    "# Copy diabetes df to diabetes_mice_imputed\n",
    "df_mice_imputed = df.copy(deep=True)\n",
    "\n",
    "# Initialize IterativeImputer\n",
    "mice_imputer = IterativeImputer()\n",
    "\n",
    "# Impute using fit_transform on df_mice_imputed\n",
    "df_mice_imputed.iloc[:, :] = mice_imputer.fit_transform(df_mice_imputed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Remember, KNN finds most similar points for imputing while MICE performs multiple regression for imputing  and is a robust method to impute missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluation Of Different Imputation Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Analyzing the performance of the different imputed models is one of the most significant tasks in dealing with missing data. It determines, the type of imputed DataFrame you can rely upon. \n",
    "\n",
    "\n",
    ">> For analysis, we can fit a linear regression model on the imputed DataFrame and check for various parameters that impact the selection of the imputation type.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaNs from DataFrame df\n",
    "df_complete_case = df.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use head to display few observations \n",
    "df_complete_case.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fit a linear model for statistical summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statsmodels.api \n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add constant to X and set X & y values to fit linear model\n",
    "X = sm.add_constant(df_complete_case.iloc[:, :-1])\n",
    "y = df_complete_case['Class']\n",
    "\n",
    "# Fit linear model\n",
    "lm = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary of lm\n",
    "print('\\nSummary: ', lm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print R squared score of Linear Model (lm)\n",
    "print('\\nAdjusted R-squared score: ', lm.rsquared_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the params of linear model (lm)\n",
    "print('\\nCoefficcients:\\n', lm.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Comparing R-squared and coefficients </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Point to Remember: \n",
    ">> R-squared measured the accuracy of the machine learning models and the higher the R-Square, the better the model.\n",
    "\n",
    ">> Coefficients explains the weights of the different features in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>> Fit linear model on different imputed DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Imputation\n",
    "y = df['Class']\n",
    "X = sm.add_constant(diabetes_mean.iloc[:, :-1])\n",
    "lm_mean = sm.OLS(y, X).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation\n",
    "X = sm.add_constant(df_knn_imputed.iloc[:, :-1])\n",
    "lm_KNN = sm.OLS(y, X).fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MICE Imputation\n",
    "X = sm.add_constant(df_mice_imputed.iloc[:, :-1])\n",
    "lm_MICE = sm.OLS(y, X).fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparing R-squared of different impuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r_squared = pd.DataFrame(\n",
    "    {'Complete Case': lm.rsquared_adj,\n",
    "     'Mean Imputation': lm_mean.rsquared_adj,\n",
    "     'KNN Imputation': lm_KNN.rsquared_adj,\n",
    "     'Mice Imputation': lm_MICE.rsquared_adj\n",
    "    },\n",
    "    index=['R-squared_adj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_r_squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Please note from above, mean imputation has the least r-squared as it imputes the same mean value throughout the feature.\n",
    "\n",
    "The complete case has the highest r-squared as half the rows with miissing values have beeen dropped. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_coefficients = pd.DataFrame(\n",
    "    {\n",
    "        'Complete Case': lm.params,\n",
    "        'Mean Imputation': lm_mean.params,\n",
    "        'KNN Imputation': lm_KNN.params,\n",
    "        'MICE Imputaion': lm_MICE.params\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print pd_coefficients\n",
    "pd_coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "Please note from above report of coefficients, we see that the feature Glucose, Diastotic_BP, and Skin_Fold add more weight to reinforce these features in the imputations.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparing Density Plots For These Impuation Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot graphs of imputed DataFrames and the complete case\n",
    "df_complete_case['Skin_Fold'].plot(kind='kde', c='red', linewidth=3)\n",
    "diabetes_mean['Skin_Fold'].plot(kind='kde')\n",
    "df_knn_imputed['Skin_Fold'].plot(kind='kde')\n",
    "df_mice_imputed['Skin_Fold'].plot(kind='kde')\n",
    "\n",
    "# Create labels for the four DataFrames\n",
    "labels = [\n",
    "    'Baseline (Complete Case)',\n",
    "    'Mean Imputation',\n",
    "    'KNN Imputation',\n",
    "    'MICE Imputation'\n",
    "]\n",
    "\n",
    "plt.legend(labels)\n",
    "\n",
    "# Set the x-label as Skin Fold\n",
    "plt.xlabel('Skin Fold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "\n",
    "Please note \n",
    "\n",
    "1. How mean imputation is completely out of shape as compared to other imputations.\n",
    "\n",
    "2. The MICE and KNN imputations looks much more similar and are close to resemble the shape of Baseline (Complete Case) distributions  \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_squares = {'Mean Imputation': lm_mean.rsquared_adj, \n",
    "             'KNN Imputation': lm_KNN.rsquared_adj, \n",
    "             'MICE Imputation': lm_MICE.rsquared_adj}\n",
    "\n",
    "# Select best R-squared\n",
    "best_imputation = max(r_squares, key=r_squares.get)\n",
    "\n",
    "print(\"The best imputation technique is: \", best_imputation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
